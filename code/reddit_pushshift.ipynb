{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Reddit API via Pushshift (psaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pushshift_data(query, subreddit, api, after, limit = 500):\n",
    "\n",
    "    gen = api.search_comments(q = query, subreddit = subreddit, after = after)\n",
    "\n",
    "    max_response_cache = limit\n",
    "    cache = []\n",
    "\n",
    "    for c in gen:\n",
    "        cache.append(c)\n",
    "        \n",
    "        if limit is not None: \n",
    "            # Omit this test to actually return all results. Wouldn't recommend it though: could take a while, but you do you.\n",
    "            if len(cache) >= max_response_cache:\n",
    "                break\n",
    "\n",
    "    # If you really want to: pick up where we left off to get the rest of the results.\n",
    "    if False:\n",
    "        for c in gen:\n",
    "            cache.append(c)\n",
    "            \n",
    "    df = pd.DataFrame([thing.d_ for thing in cache])\n",
    "    \n",
    "    return(df)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes|Diabetes|\"I was just diagnosed with diabetes\"|\"today I was diagnosed with diabetes\"|\"I just learned I have diabetes\"|\"learned I got diabetes\"|\"heard I got diabetes\"|\"learned I have diabetes\"|\"heard I have diabetes\"|\"I was recently diagnosed with diabetes\"|\"I recently learned I have diabetes\"|\"I recently learned that I have diabetes\"|\"new diabetic\"|\"New diabetic\"|\"NEW DIABETIC\"\n"
     ]
    }
   ],
   "source": [
    "diabetes_terms =  [\"diabetes\",\n",
    "                   \"Diabetes\",\n",
    "                   '\"I was just diagnosed with diabetes\"',\n",
    "                   '\"today I was diagnosed with diabetes\"',\n",
    "                   '\"I just learned I have diabetes\"',\n",
    "                   '\"learned I got diabetes\"',\n",
    "                   '\"heard I got diabetes\"',\n",
    "                   '\"learned I have diabetes\"',\n",
    "                   '\"heard I have diabetes\"',\n",
    "                   '\"I was recently diagnosed with diabetes\"',\n",
    "                   '\"I recently learned I have diabetes\"',\n",
    "                   '\"I recently learned that I have diabetes\"',\n",
    "                   '\"new diabetic\"',\n",
    "                   '\"New diabetic\"',\n",
    "                   '\"NEW DIABETIC\"']\n",
    "\n",
    "diabetes_query = '|'.join(diabetes_terms)\n",
    "\n",
    "print(diabetes_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19103 posts.\n",
      "  all_awardings associated_award          author  \\\n",
      "0            []             None    crappysurfer   \n",
      "1            []             None        adam_mmm   \n",
      "2            []             None  NebrasketballN   \n",
      "3            []             None    badnewsblair   \n",
      "4            []             None       Lausannea   \n",
      "\n",
      "  author_flair_background_color author_flair_css_class  \\\n",
      "0                                                   T1   \n",
      "1                          None                   None   \n",
      "2                          None                   None   \n",
      "3                                                   T2   \n",
      "4                       #0079d3           user-type-15   \n",
      "\n",
      "                               author_flair_richtext  \\\n",
      "0                    [{'e': 'text', 't': 'T1 1996'}]   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [{'e': 'text', 't': 'T2, 2015, Metformin/Lower...   \n",
      "4  [{'e': 'text', 't': 'LADA/1.5 dx 2011 / 640G +...   \n",
      "\n",
      "               author_flair_template_id                    author_flair_text  \\\n",
      "0                                  None                              T1 1996   \n",
      "1                                  None                                 None   \n",
      "2                                  None                                 None   \n",
      "3                                  None  T2, 2015, Metformin/Lower Carb Diet   \n",
      "4  73403a0e-251a-11e1-84b1-12313d096aae    LADA/1.5 dx 2011 / 640G + Libre 2   \n",
      "\n",
      "  author_flair_text_color author_flair_type  ... subreddit subreddit_id  \\\n",
      "0                    dark          richtext  ...  diabetes     t5_2qhsj   \n",
      "1                    None              text  ...  diabetes     t5_2qhsj   \n",
      "2                    None              text  ...  diabetes     t5_2qhsj   \n",
      "3                    dark          richtext  ...  diabetes     t5_2qhsj   \n",
      "4                    dark          richtext  ...  diabetes     t5_2qhsj   \n",
      "\n",
      "  top_awarded_type total_awards_received treatment_tags       created  \\\n",
      "0              NaN                     0             []  1.624019e+09   \n",
      "1              NaN                     0             []  1.624018e+09   \n",
      "2              NaN                     0             []  1.624017e+09   \n",
      "3              NaN                     0             []  1.624016e+09   \n",
      "4              NaN                     0             []  1.624016e+09   \n",
      "\n",
      "   distinguished  author_cakeday edited steward_reports  \n",
      "0            NaN             NaN    NaN             NaN  \n",
      "1            NaN             NaN    NaN             NaN  \n",
      "2            NaN             NaN    NaN             NaN  \n",
      "3            NaN             NaN    NaN             NaN  \n",
      "4            NaN             NaN    NaN             NaN  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "start_epoch=int(dt.datetime(2020, 1, 1).timestamp()) # Set filtering date to 1st of January 2020\n",
    "\n",
    "df = get_pushshift_data(query = diabetes_query,\n",
    "                        subreddit = \"diabetes\",\n",
    "                        api = api,\n",
    "                        after = start_epoch,\n",
    "                        limit = None)\n",
    "\n",
    "print(\"Found\", len(df), \"posts.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and remove anniversaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566 comments from past diabetes diagnoses\n",
      "18537 comments from recent diabetes diagnoses\n"
     ]
    }
   ],
   "source": [
    "# many users post about a diagnosis anniversary, remove these tweets as well\n",
    "df['recent'] = df['body'].apply(lambda x: ('years ago' not in x) and \\\n",
    "                                              ('yrs ago' not in x) and \\\n",
    "                                              ('year ago' not in x) and \\\n",
    "                                              ('YEARS AGO' not in x) and \\\n",
    "                                              ('years today' not in x) and \\\n",
    "                                              ('flashback') not in x)\n",
    "\n",
    "\n",
    "past = df[df['recent'] == False].copy()\n",
    "recent = df[df['recent'] == True].copy()\n",
    "\n",
    "print('{} comments from past diabetes diagnoses'.format(len(past)))\n",
    "print('{} comments from recent diabetes diagnoses'.format(len(recent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 5408 usernames.\n"
     ]
    }
   ],
   "source": [
    "recent.to_csv(join(src, 'reddit_diagnosed_diabetes_clean.csv'), index=False)\n",
    "\n",
    "user_list = list(recent['author'].unique())\n",
    "print('Saving {} usernames.'.format(len(user_list)))\n",
    "\n",
    "with open(join(src, \"reddit_diagnosed_user_IDs.txt\"), \"w\") as outfile:\n",
    "    for username in user_list:\n",
    "        outfile.write(\"%s\\n\" % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_dates = df[['author', 'created_utc', 'id']]\\\n",
    "    .sort_values(by=['author', 'created_utc'])\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .drop_duplicates(subset=['author'])\n",
    "    \n",
    "diagnosis_dates['created_dt'] = diagnosis_dates['created_utc'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S')\n",
    ")\n",
    "\n",
    "diagnosis_dates.to_csv(join(src, 'reddit_user_diagnosis_dates.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sicss2021",
   "language": "python",
   "name": "sicss2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
